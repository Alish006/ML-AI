{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1 - Computing CNN Memory Usage**\n",
        "\n",
        "Let us assume you have built a CNN with following details\n",
        "It consists of three convolutional layers, each with 3 x 3 kernels,\n",
        "a stride of 2, and SAME padding.\n",
        "\n",
        "o The first layer outputs 100 feature maps\n",
        "\n",
        "o The second layer outputs 200 feature maps\n",
        "\n",
        "o The third layer outputs 400 feature maps\n",
        "The input images are RGB images of 720 x 1280 pixels."
      ],
      "metadata": {
        "id": "la7uGUQVjYcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions\n",
        "\n",
        "*What is the total number of parameters in CNN?*\n",
        "\n",
        "\n",
        "(3 * 3 * 3) * 1 = 27(weights) + 1 (bias) = 28 with 1 input feature\n",
        "\n",
        "first layer: (3 * 3 * 3) * 100 = 2700(weights) + 100(bias per weight) = 2800\n",
        "\n",
        "second layer: (3 * 3 * 100) * 200 = 180 000(weights) + 200(bias per weight) = 180 200\n",
        "\n",
        "third layer: (3 * 3 * 200) * 400 = 720 000(weights) + 400(bias per weight) =\n",
        "720 400\n",
        "\n",
        "Total number of parameters: 2800 + 180 200 + 720 400 = 903 400\n",
        "--------------------------------------------------------------\n",
        "\n",
        "*What is the minimum total RAM needed, if parameters are stored in 32-bit floats.\n",
        "Assume making predictions for a single image.*\n",
        "\n",
        "**This is the minimum, counting only model parameters for inference on one image:**\n",
        "\n",
        "1 parameter = 32 bits = 4 bytes = 903 400 * 4 = 3 613 600 bytes ~ 3.45 MB\n",
        "---------------------------------------\n",
        "*How does the answer to question 2 change if everything is stored in 8-bit floats.\n",
        "Assume making predictions for a single image.*\n",
        "\n",
        "1 parameter = 1 byte = 903 400 * 1  = 903 400 bytes ~ 0.86 MB\n",
        "--------------------------------------\n",
        "*How does the answer to question 2 change when training on a mini-batch of 20\n",
        "images?*\n",
        "\n",
        "Parameters: 3.45MB\n",
        "\n",
        "Gradients: +3.45MB\n",
        "\n",
        "Activations: scale with batch size --> much larger\n",
        "\n",
        "So RAM increases significantly, roughly several times the inference RAM.\n",
        "\n",
        "Parameters alone do not change, but training memory grows because of gradients and activations.\n"
      ],
      "metadata": {
        "id": "EhPmPzDMj4r5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbZtKfkCFSez"
      },
      "outputs": [],
      "source": [
        "#import needed libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import datasets, layers, models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "jSeYlLXJGUVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c12493-dffd-4842-c0f2-95036041cdc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x_tarin:\", x_train.shape)\n",
        "print(\"x_test:\", x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zg-0fce0K_9A",
        "outputId": "c41b2cdf-39c2-445b-9683-d198992dd595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_tarin: (60000, 28, 28)\n",
            "x_test: (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the dataset\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0"
      ],
      "metadata": {
        "id": "_sUMFTWpK20C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape the dataset\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test  = x_test.reshape(-1, 28, 28, 1)"
      ],
      "metadata": {
        "id": "YmmhT8D-fdsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for plot learning curves\n",
        "def plot_learning_curve(history, title):\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['loss'], label='Training loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "BaLuVXXyMwff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Augmentation** is a technique of artificially increasing the training set by creating modified copies of a dataset using existing data."
      ],
      "metadata": {
        "id": "XTKjzsqNnVaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data augmentation technique\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "])"
      ],
      "metadata": {
        "id": "obkGuLBiZzIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning Rate Scheduler** - for automatically adjust learning rate"
      ],
      "metadata": {
        "id": "1ycES0IA18aT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define learning rate scheduler\n",
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',  # reduce LR when validation loss stops improving\n",
        "    factor=0.5,          # reduce LR by half\n",
        "    patience=3,          # wait 3 epochs before reducing\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "viJBs8x2cxJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "# data augmentation\n",
        "model.add(data_augmentation)\n",
        "\n",
        "# convolution layer\n",
        "model.add(layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1)))\n",
        "# batch normalization\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "# convolution layer\n",
        "model.add(layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1)))\n",
        "# batch normalization\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "# max pooling layer - for reducing image size\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# dropout - regualization technique to prevent overfitting\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "# convert to one-dimensional arrays\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# dense layer or fully connected layer\n",
        "model.add(layers.Dense(128, activation=\"relu\"))\n",
        "# batch normalization\n",
        "model.add(layers.BatchNormalization())\n",
        "# dropout - regualization technique to prevent overfitting\n",
        "model.add(layers.Dropout(0.50))\n",
        "\n",
        "# output layer\n",
        "model.add(layers.Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "ODD-oRIlM7zE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c43a56d-9f89-472e-abee-3b6a9b830b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# settings how the model should learn\n",
        "model.compile(\n",
        "    # The optimizer controls how the network updates its weights\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    # Loss function measures how far the model’s predictions are from the true labels\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    # Metrics are used to monitor the model’s performance.\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "xjSZxe9ebVzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks = [lr_scheduler]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3-op6BTcJcv",
        "outputId": "8f294c37-a7e2-4b3a-fd52-d53ed143b574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 219ms/step - accuracy: 0.7045 - loss: 0.8830 - val_accuracy: 0.8288 - val_loss: 0.4628 - learning_rate: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 219ms/step - accuracy: 0.8178 - loss: 0.5092 - val_accuracy: 0.8582 - val_loss: 0.3920 - learning_rate: 0.0010\n",
            "Epoch 3/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the model loss diagram"
      ],
      "metadata": {
        "id": "VRDnDI71qiOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_curve(history, \"CNN Model\")"
      ],
      "metadata": {
        "id": "OgUj7dbLp7SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training loss approximately is 0.36 or less.\n",
        "\n",
        "Validation loss approximately is 0.30.\n",
        "\n",
        "Validation loss showed less loss than Training loss in different 6%."
      ],
      "metadata": {
        "id": "TMIP4r51qqHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model accuracy and loss using test set"
      ],
      "metadata": {
        "id": "5tc998udqZ-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Test loss:\", model_accuracy[0])\n",
        "print(\"Test accuracy:\", model_accuracy[1])"
      ],
      "metadata": {
        "id": "pFvgEWXiqEj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "\n",
        "In this lab 6, we implemented CNN model for classify **FASHION MNIST Dataset** that 10 classes of images with diffrenet layers as convolution, max-poolling, and dense. For optimizing the trainnig process of model, we added adam optimizer, and learning rate scheduler for adjustiong the learning rate during the training process of the model. In addition, we used data augmentation for increasing the accuracy of the model in different shape of the image. The model shows high accuracy and less loss: 88% and 32%."
      ],
      "metadata": {
        "id": "JBsX7Y3H0W88"
      }
    }
  ]
}